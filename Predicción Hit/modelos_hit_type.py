# -*- coding: utf-8 -*-
"""Modelos_Hit_Type.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tDO0tOb2exTUvd_rGozvMlJ4i3ad_UHq

# Predicción de Tipo de Remate
"""

# Paso 1: Cargar y preparar el dataset
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFE
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, mean_absolute_error, brier_score_loss, log_loss
from sklearn.preprocessing import label_binarize

# Cargar el dataset
df = pd.read_csv('../dataset_full.csv', sep=',')

# Definir columnas
categorical_features = ['pass_rating', 'set_type', 'set_location',
                        'serve_type', 'team']
numeric_features = ['receive_location', 'digger_location', 'pass_land_location',
                    'hitter_location', 'num_blockers']

# Filtrar datos con hit_type no nulo
df_filtered = df[categorical_features + numeric_features + ['hit_type']].copy()
df_filtered = df_filtered[df_filtered['hit_type'].notna()]

# Imputar y formatear datos
for col in categorical_features:
    df_filtered[col] = df_filtered[col].fillna('missing').astype(str)
for col in numeric_features:
    df_filtered[col] = df_filtered[col].fillna(-1)

# X e y
X = df_filtered.drop(columns='hit_type')
y = df_filtered['hit_type'].astype(str)

# Preprocesamiento
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)
X_encoded = preprocessor.fit_transform(X)

# Obtener nombres de columnas transformadas
ohe = preprocessor.named_transformers_['cat']
encoded_feature_names = list(ohe.get_feature_names_out(categorical_features)) + numeric_features

# Feature selection con RFE
estimator = RandomForestClassifier(n_estimators=100, random_state=42)
selector = RFE(estimator, n_features_to_select=20, step=10)
selector.fit(X_encoded, y)

# Seleccionar features
X_selected = X_encoded[:, selector.support_]

# División de datos
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

"""## Modelo Random Forest"""

# Entrenar Random Forest con features seleccionadas
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predicción y evaluación
y_pred = rf_model.predict(X_test)
report = classification_report(y_test, y_pred, output_dict=True)
cm = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)

# Evaluación
print("Reporte de clasificación Random Forest:")
print(classification_report(y_test, y_pred))

# Binariza usando las clases del modelo
y_test_bin = label_binarize(y_test, classes=rf_model.classes_)
# Definir las clases usando el modelo entrenado
classes = rf_model.classes_

# --- RANDOM FOREST ---
y_proba_rf = rf_model.predict_proba(X_test)
print("Random Forest:")
for i, clase in enumerate(classes):
    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba_rf[:, i])
    auc_score = roc_auc_score(y_test_bin[:, i], y_proba_rf[:, i])
    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name=f"RF - {clase}").plot()
    plt.title(f"Curva ROC - Random Forest - Clase {clase}")
    plt.show()
    print(f"AUC (Clase {clase}): {auc_score:.4f}")
mae_rf = mean_absolute_error(y_test_bin, y_proba_rf)
brier_rf = np.mean([brier_score_loss(y_test_bin[:, i], y_proba_rf[:, i]) for i in range(len(rf_model.classes_))])
print(f"MAE RF: {mae_rf:.4f}")
print(f"Brier Score RF: {brier_rf:.4f}")

# Visualización de la matriz de confusión
plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=rf_model.classes_, yticklabels=rf_model.classes_, cmap='Blues')
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.title("Matriz de Confusión - Random Forest (hit_type)")
plt.tight_layout()
plt.show()

"""## Modelo SVM"""

# Escalar los datos y entrenar SVM
svm_pipeline = Pipeline([
    ('scaler', StandardScaler(with_mean=False)),  # Escalado necesario para SVM
    ('svc', SVC(kernel='rbf', C=1, gamma='scale', probability=True))  # Puedes ajustar kernel, C y gamma
])

# Entrenamiento
svm_pipeline.fit(X_train, y_train)

# Predicción
y_pred_svm = svm_pipeline.predict(X_test)
y_proba_svm = svm_pipeline.predict_proba(X_test)
classes_svm = svm_pipeline.classes_
y_test_bin_svm = label_binarize(y_test, classes=classes_svm)
# Mostrar la curva ROC para cada clase
print("SVM:")
for i, clase in enumerate(classes_svm):
    fpr, tpr, _ = roc_curve(y_test_bin_svm[:, i], y_proba_svm[:, i])
    auc_score = roc_auc_score(y_test_bin_svm[:, i], y_proba_svm[:, i])
    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name=f"SVM - {clase}").plot()
    plt.title(f"Curva ROC - SVM - Clase {clase}")
    plt.show()
    print(f"AUC (Clase {clase}): {auc_score:.4f}")
# Calcular MAE y Brier Score
mae_svm = mean_absolute_error(y_test_bin_svm, y_proba_svm)
brier_svm = np.mean([brier_score_loss(y_test_bin_svm[:, i], y_proba_svm[:, i]) for i in range(len(classes_svm))])
print(f"MAE SVM: {mae_svm:.4f}")
print(f"Brier Score SVM: {brier_svm:.4f}")

# Evaluación
print("Reporte de clasificación SVM:")
print(classification_report(y_test, y_pred_svm))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred_svm, labels=svm_pipeline.classes_)
plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=svm_pipeline.classes_, yticklabels=svm_pipeline.classes_)
plt.title("Matriz de Confusión - SVM (hit_type)")
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.tight_layout()
plt.show()

"""## Modelo KNN"""

# Crear y entrenar modelo KNN
knn_model = KNeighborsClassifier(n_neighbors=5)  # puedes ajustar el valor de k
knn_model.fit(X_train, y_train)

# Predicción
y_pred_knn = knn_model.predict(X_test)
y_proba_knn = knn_model.predict_proba(X_test)
classes_knn = knn_model.classes_
y_test_bin_knn = label_binarize(y_test, classes=classes_knn)

# Mostrar la curva ROC para cada clase
print("KNN:")
for i, clase in enumerate(classes_knn):
    fpr, tpr, _ = roc_curve(y_test_bin_knn[:, i], y_proba_knn[:, i])
    auc_score = roc_auc_score(y_test_bin_knn[:, i], y_proba_knn[:, i])
    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc_score, estimator_name=f"KNN - {clase}").plot()
    plt.title(f"Curva ROC - KNN - Clase {clase}")
    plt.show()
    print(f"AUC (Clase {clase}): {auc_score:.4f}")
mae_knn = mean_absolute_error(y_test_bin_knn, y_proba_knn)
brier_knn = np.mean([brier_score_loss(y_test_bin_knn[:, i], y_proba_knn[:, i]) for i in range(len(classes_knn))])
# Mostrar MAE y Brier Score
print(f"MAE KNN: {mae_knn:.4f}")
print(f"Brier Score KNN: {brier_knn:.4f}")

# Evaluación
print("Reporte de clasificación KNN:")
print(classification_report(y_test, y_pred_knn))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred_knn, labels=knn_model.classes_)
plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=knn_model.classes_, yticklabels=knn_model.classes_)
plt.title("Matriz de Confusión - KNN (hit_type)")
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.tight_layout()
plt.show()
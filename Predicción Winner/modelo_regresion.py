# -*- coding: utf-8 -*-
"""Modelo_Regresion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N94fdduMGMErtTtvzm6gSCXtvlQtZvdE

# Modelo Regresión Logística
"""

import matplotlib
#matplotlib.use('TkAgg')
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import brier_score_loss

# Cargar el dataset
df = pd.read_csv('../dataset_full.csv', sep=',')

"""## Selección de Columnas Categóricas
Se realizará una selección de columnas categóricas sobre las que aplicaremos ***one hot encoding*** ya que son columnas que contienen variables categóricas (tipo texto o etiquetas). Dentro de estas columnas encontramos: `pass_rating`, `set_type`, `set_location`, `hit_type`, `block_touch`, `serve_type`, `win_reason`, `lose_reason`, `winning_team` y `team`.
Añadiremos el resto de columnas útiles para entrenar el modelo dentro de la variable `features`.
"""

# Columnas categóricas
# No se utilizarán las columnas `win_reason` y `lose_reason` ya que la información
# la aportan después de conocer el resultado del rally.
categorical_features = ['pass_rating', 'set_type', 'set_location', 'hit_type',
                        'block_touch', 'serve_type', 'team']

# Columnas numéricas útiles para el modelo
features = categorical_features + [
    'receive_location', 'digger_location', 'pass_land_location',
    'hitter_location', 'hit_land_location', 'num_blockers'
]

"""## Imputar Nulos
Al entrenar el modelo tenemos que saber que las filas que contengan algún valor nulo no nos servirán para entrenar el mismo. Es por ello que se han modificado las filas con valores nulos, sustityuendo estos por el valor `mising` en las columnas categóricas y por el valor `-1` en las columnas numéricas.
"""

# Imputar nulos
df_imputed = df[features].copy()
for col in categorical_features:
    df_imputed[col] = df_imputed[col].fillna('missing')
for col in ['receive_location', 'digger_location', 'pass_land_location',
            'hitter_location', 'hit_land_location', 'num_blockers']:
    df_imputed[col] = df_imputed[col].fillna(-1)

"""## Target
En este primer modelo crearemos una columna target con el objetivo de predecir si el equipo que está realizando la ronda será el ganador del rally.

"""

# Crear columna objetivo
# El modelo aprende a predecir si el equipo que está realizando esta jugada va a ser el que eventualmente gane el rally completo.
# Se crea una columna `target` que indica si el equipo actual (`team`) es el mismo que el equipo ganador del rally (`winning_team`).
# Los valores de `target` serán 1 si el equipo actual es el ganador y 0 en caso contrario.
df_imputed['target'] = (df['team'] == df['winning_team']).astype(int)

"""## Procesamiento
Separaremos la columna target del resto. Aplicaremos finalmente one hot encoder sobre las columnas categóricas y crearemos el modelo de regresión logística
"""

# Separar variables
X = df_imputed.drop(columns='target')
y = df_imputed['target']
# División de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Pipeline de preprocesamiento y modelo
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='passthrough'
)
# Pipeline de modelo
# Se utiliza un modelo de regresión logística para predecir la variable objetivo.
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

"""## Entrenamiento y clasificación del modelo

Finalmente dividiremos los datos de forma aleatoria en un 80% para entrenar el modelo y un 20% sobre el que aplicaremos el mismo para validarlo.
"""


# Entrenamiento del modelo
model.fit(X_train, y_train)
# Predicción de resultados
y_pred = model.predict(X_test)

"""## Resultados"""

# Obtener probabilidades predichas para la clase positiva
y_proba = model.predict_proba(X_test)[:, 1]

# Mostrar la curva ROC
RocCurveDisplay.from_estimator(model, X_test, y_test)
plt.title('Curva ROC (Regresión Logística)')
plt.show()

# Calcular AUC
auc = roc_auc_score(y_test, y_proba)
print(f'AUC: {auc:.4f}')

# Calcular MAE
mae = mean_absolute_error(y_test, y_pred)
print(f'Error Absoluto Medio (MAE): {mae:.4f}')

# Calcular Brier Score
brier = brier_score_loss(y_test, y_proba)
print(f'Brier Score: {brier:.4f}')

# Clasificación del modelo
print(classification_report(y_test, y_pred))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No ganó', 'Ganó'])
disp.plot(cmap='Blues')
plt.title('Matriz de Confusión (Regresion Logística)')
plt.grid(False)
plt.show()
